{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20c5d195",
   "metadata": {
    "id": "20c5d195",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped 2248.2004-09-23.GP.spam.txt\n",
      "skipped 2526.2004-10-17.GP.spam.txt\n",
      "skipped 2698.2004-10-31.GP.spam.txt\n",
      "skipped 4566.2005-05-24.GP.spam.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nEmail Classifier Data:\\n- 'name': Filename\\n- 'content': Email content\\n- 'category': Category of the email (ham/spam)\\n\\nham: List of dictionaries containing information from ham (non-spam) emails.\\nspam: List of dictionaries containing information from spam emails.\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_spam():\n",
    "    \"\"\"\n",
    "    Reads and extracts information from spam emails.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries containing email information.\n",
    "        Each dictionary has the following keys:\n",
    "        - 'name': The filename.\n",
    "        - 'content': The email content.\n",
    "        - 'category': The category (spam).\n",
    "    \"\"\"\n",
    "    category = 'spam'\n",
    "    directory = './enron1/enron1/spam'\n",
    "    return read_category(category, directory)\n",
    "\n",
    "def read_ham():\n",
    "    \"\"\"\n",
    "    Reads and extracts information from ham (non-spam) emails.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries containing email information.\n",
    "        Each dictionary has the following keys:\n",
    "        - 'name': The filename.\n",
    "        - 'content': The email content.\n",
    "        - 'category': The category (ham).\n",
    "    \"\"\"\n",
    "    category = 'ham'\n",
    "    directory = './enron1/enron1/ham'\n",
    "    return read_category(category, directory)\n",
    "\n",
    "def read_category(category, directory):\n",
    "    \"\"\"\n",
    "    Reads and extracts information from emails in a specified category.\n",
    "\n",
    "    Args:\n",
    "    category (str): The category of emails (ham or spam).\n",
    "    directory (str): The directory containing the email files.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of dictionaries containing email information.\n",
    "        Each dictionary has the following keys:\n",
    "        - 'name': The filename.\n",
    "        - 'content': The email content.\n",
    "        - 'category': The category (ham or spam).\n",
    "    \"\"\"\n",
    "    emails = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if not filename.endswith(\".txt\"):\n",
    "            continue\n",
    "        with open(os.path.join(directory, filename), 'r') as fp:\n",
    "            try:\n",
    "                content = fp.read()\n",
    "                emails.append({'name': filename, 'content': content, 'category': category})\n",
    "            except:\n",
    "                print(f'skipped {filename}')\n",
    "    return emails\n",
    "\n",
    "# Read ham (non-spam) and spam emails\n",
    "ham = read_ham()\n",
    "spam = read_spam()\n",
    "\n",
    "# Create a DataFrame to store the email data\n",
    "df = pd.DataFrame.from_records(ham)\n",
    "df = pd.concat([df, pd.DataFrame.from_records(spam)], ignore_index=True)\n",
    "\n",
    "\"\"\"\n",
    "Email Classifier Data:\n",
    "- 'name': Filename\n",
    "- 'content': Email content\n",
    "- 'category': Category of the email (ham/spam)\n",
    "\n",
    "ham: List of dictionaries containing information from ham (non-spam) emails.\n",
    "spam: List of dictionaries containing information from spam emails.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d5be7df-8ec7-48bb-8ba8-7ab3d1b2cd10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001.1999-12-10.farmer.ham.txt</td>\n",
       "      <td>Subject: christmas tree farm pictures\\n</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.1999-12-13.farmer.ham.txt</td>\n",
       "      <td>Subject: vastar resources , inc .\\ngary , prod...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003.1999-12-14.farmer.ham.txt</td>\n",
       "      <td>Subject: calpine daily gas nomination\\n- calpi...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004.1999-12-14.farmer.ham.txt</td>\n",
       "      <td>Subject: re : issue\\nfyi - see note below - al...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005.1999-12-14.farmer.ham.txt</td>\n",
       "      <td>Subject: meter 7268 nov allocation\\nfyi .\\n- -...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name  \\\n",
       "0  0001.1999-12-10.farmer.ham.txt   \n",
       "1  0002.1999-12-13.farmer.ham.txt   \n",
       "2  0003.1999-12-14.farmer.ham.txt   \n",
       "3  0004.1999-12-14.farmer.ham.txt   \n",
       "4  0005.1999-12-14.farmer.ham.txt   \n",
       "\n",
       "                                             content category  \n",
       "0            Subject: christmas tree farm pictures\\n      ham  \n",
       "1  Subject: vastar resources , inc .\\ngary , prod...      ham  \n",
       "2  Subject: calpine daily gas nomination\\n- calpi...      ham  \n",
       "3  Subject: re : issue\\nfyi - see note below - al...      ham  \n",
       "4  Subject: meter 7268 nov allocation\\nfyi .\\n- -...      ham  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c23fd",
   "metadata": {
    "id": "1a1c23fd"
   },
   "source": [
    "# Data cleaning \n",
    "The 'preprocessor' function accepts a string as input, and its purpose is to replace all characters that are not part of the alphabet with a space. Subsequently, it converts the entire string to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c447c901",
   "metadata": {
    "id": "c447c901",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocessor(df, column_name):\n",
    "    df[column_name] = df[column_name].apply(lambda text: re.sub(r'[^a-zA-Z]', ' ', text).lower())\n",
    "\n",
    "\n",
    "preprocessor(df,'content')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "712b7853-6caa-4c5e-8447-19de7599b748",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001.1999-12-10.farmer.ham.txt</td>\n",
       "      <td>subject  christmas tree farm pictures</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002.1999-12-13.farmer.ham.txt</td>\n",
       "      <td>subject  vastar resources   inc   gary   produ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003.1999-12-14.farmer.ham.txt</td>\n",
       "      <td>subject  calpine daily gas nomination   calpin...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004.1999-12-14.farmer.ham.txt</td>\n",
       "      <td>subject  re   issue fyi   see note below   alr...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0005.1999-12-14.farmer.ham.txt</td>\n",
       "      <td>subject  meter      nov allocation fyi        ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name  \\\n",
       "0  0001.1999-12-10.farmer.ham.txt   \n",
       "1  0002.1999-12-13.farmer.ham.txt   \n",
       "2  0003.1999-12-14.farmer.ham.txt   \n",
       "3  0004.1999-12-14.farmer.ham.txt   \n",
       "4  0005.1999-12-14.farmer.ham.txt   \n",
       "\n",
       "                                             content category  \n",
       "0             subject  christmas tree farm pictures       ham  \n",
       "1  subject  vastar resources   inc   gary   produ...      ham  \n",
       "2  subject  calpine daily gas nomination   calpin...      ham  \n",
       "3  subject  re   issue fyi   see note below   alr...      ham  \n",
       "4  subject  meter      nov allocation fyi        ...      ham  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474108e6-40f4-4ba9-bd63-fe6c935abf79",
   "metadata": {},
   "source": [
    "# Data cleaning end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc910d0-eee7-4ea9-814f-96d715074da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1442d377",
   "metadata": {
    "id": "1442d377",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9622823984526112\n",
      "Confusion Matrix:\n",
      "[[714  15]\n",
      " [ 24 281]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      0.98      0.97       729\n",
      "        spam       0.95      0.92      0.94       305\n",
      "\n",
      "    accuracy                           0.96      1034\n",
      "   macro avg       0.96      0.95      0.95      1034\n",
      "weighted avg       0.96      0.96      0.96      1034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Definition of the preprocessor function\n",
    "def preprocessor(text):\n",
    "    \"\"\"\n",
    "    Preprocesses text by removing non-alphabet characters and converting to lowercase.\n",
    "\n",
    "    Args:\n",
    "    text (str): The input text to be preprocessed.\n",
    "\n",
    "    Returns:\n",
    "    str: The preprocessed text.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^a-zA-Z]', ' ', text).lower()\n",
    "\n",
    "# Creating a text vectorizer\n",
    "vectorizer = CountVectorizer(preprocessor=preprocessor)\n",
    "\n",
    "# Transforming text data into a feature matrix\n",
    "X = vectorizer.fit_transform(df['content'])\n",
    "y = df['category']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Creating and training the logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Model evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Classification Report:\\n{class_report}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674d032",
   "metadata": {
    "id": "9674d032"
   },
   "source": [
    "Conclusion:\n",
    "# dataset:enron1 \n",
    "According to the results, the model achieves an accuracy of approximately 96.23% in classifying emails as \"ham\" or \"spam.\" The classification report provides additional details about the model's performance for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b7d78c9",
   "metadata": {
    "id": "6b7d78c9",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Positive Features (Spam-related):\n",
      "cards\n",
      "document\n",
      "removed\n",
      "smart\n",
      "laptop\n",
      "women\n",
      "enjoy\n",
      "school\n",
      "note\n",
      "read\n",
      "\n",
      "Top 10 Negative Features (Ham-related):\n",
      "revised\n",
      "actuals\n",
      "attached\n",
      "check\n",
      "see\n",
      "xls\n",
      "hpl\n",
      "nom\n",
      "tap\n",
      "for\n",
      "\n",
      "Top 10 Negative Features (Spam-negative):\n",
      "revised\n",
      "actuals\n",
      "attached\n",
      "check\n",
      "see\n",
      "xls\n",
      "hpl\n",
      "nom\n",
      "tap\n",
      "for\n",
      "\n",
      "Top 10 Positive Features (Ham-positive):\n",
      "cards\n",
      "document\n",
      "removed\n",
      "smart\n",
      "laptop\n",
      "women\n",
      "enjoy\n",
      "school\n",
      "note\n",
      "read\n"
     ]
    }
   ],
   "source": [
    "# Retrieving the feature names from the vectorizer\n",
    "features = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Extracting \n",
    "top_positive_features = [features[i] for i in coefficients.argsort()[-10:][::-1]]\n",
    "top_negative_features = [features[i] for i in coefficients.argsort()[:10]]\n",
    "top_spam_negative_features = [features[i] for i in coefficients.argsort()[:10]]\n",
    "top_ham_positive_features = [features[i] for i in coefficients.argsort()[-10:][::-1]]\n",
    "\n",
    "# Printing the top positive (spam-related) features\n",
    "print(\"Top 10 Positive Features (Spam-related):\")\n",
    "for feature in top_positive_features:\n",
    "    print(feature)\n",
    "\n",
    "# Printing the top negative (ham-related) features\n",
    "print(\"\\nTop 10 Negative Features (Ham-related):\")\n",
    "for feature in top_negative_features:\n",
    "    print(feature)\n",
    "\n",
    "# Printing the top negative (spam-related) features\n",
    "print(\"\\nTop 10 Negative Features (Spam-negative):\")\n",
    "for feature in top_spam_negative_features:\n",
    "    print(feature)\n",
    "\n",
    "# Printing the top positive (ham-related) features\n",
    "print(\"\\nTop 10 Positive Features (Ham-positive):\")\n",
    "for feature in top_ham_positive_features:\n",
    "    print(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c436a07-b4fa-4545-b9d5-85b5749374c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
